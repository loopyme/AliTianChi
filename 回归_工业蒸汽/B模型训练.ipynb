{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PartB 模型训练_融合\n",
    "\n",
    "主要包括:\n",
    " - 基于Kfold的交叉验证 \n",
    " - xgboost            默认回归器的训练\n",
    " - GradientBoosting   默认回归器的训练\n",
    " - LightGBM           默认回归器的训练\n",
    " - catboost           默认回归器的训练\n",
    " - 以上四个模型的Stacking(基于xgboost模型)\n",
    "\n",
    "TODO:\n",
    " - [ ] xgboost          回归器的调参\n",
    " - [ ] GradientBoosting 回归器的调参\n",
    " - [ ] LightGBM         回归器的调参\n",
    " - [ ] catboost         回归器的调参\n",
    " \n",
    "结果:\n",
    "\n",
    "- 这只是**模型融合的空框架**，如果不特征工程，在不调参的情况下，**直接跑线上MSE是0.1328**\n",
    "- Stacking直接用Ridge会欠拟合,线上0.1623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "!ls datalab/231693\n",
    "!ls\n",
    "!rm -rf temp_model\n",
    "!mkdir temp_model\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装catboost\n",
    "!pip3 install catboost -i https://mirrors.aliyun.com/pypi/simple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=pd.read_csv('myspace/steam_train_washed_v.csv').drop('Unnamed: 0',axis=1)\n",
    "data = pd.read_csv('datalab/231693/zhengqi_train.txt',encoding='gbk',sep=\"\\t\")\n",
    "Y = data[\"target\"]               \n",
    "X = data.drop(['target'],axis=1).drop(['V5','V9','V11','V14','V17','V22','V28'],axis=1)\n",
    "\n",
    "# init a scaler\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "scale = False\n",
    "\n",
    "# init a kfold to split dataset\n",
    "kfold = KFold(n_splits=15, shuffle = True, random_state= 6666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training and evaluating tool\n",
    "def run_model(model,model_type):\n",
    "    global scale\n",
    "    mse,i = [],0\n",
    "    for train, test in kfold.split(X):\n",
    "        # split & scale(optional) the dataset\n",
    "        if scale:\n",
    "            X_train, y_train  = scaler.transform(X.iloc[train]), Y.iloc[train]\n",
    "            X_test,  y_test   = scaler.transform(X.iloc[test]),  Y.iloc[test]\n",
    "        else:\n",
    "            X_train, y_train  = X.iloc[train], Y.iloc[train]\n",
    "            X_test,  y_test   = X.iloc[test],  Y.iloc[test]\n",
    "\n",
    "        # fit & evaluate the model\n",
    "        model.fit(X_train,y_train) \n",
    "        mse.append(MSE(y_test, model.predict(X_test)))\n",
    "\n",
    "        # print & save the model\n",
    "        # print(i,mse[-1])\n",
    "        joblib.dump(filename=\"./temp_model/\"+str(model_type)+str(i),value=model)\n",
    "        i+=1\n",
    "    #print(model_type,np.mean(mse))\n",
    "    return np.mean(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "model = XGBRegressor(learning_rate=0.07,n_estimators=100,max_depth=5,min_child_weight=3,seed=0,subsample=0.5,colsample_bytree=0.9,gamma=0.2,reg_alpha=0.05,reg_lambda=0.1)\n",
    "\n",
    "run_model(model,\"XGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GradientBoosting\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "model = GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
    "                                  learning_rate=0.03, loss='huber', max_depth=14,\n",
    "                                  max_features='sqrt', max_leaf_nodes=None,\n",
    "                                  min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                  min_samples_leaf=10, min_samples_split=40,\n",
    "                                  min_weight_fraction_leaf=0.0, n_estimators=300,\n",
    "                                  presort='auto', random_state=10, subsample=0.8, verbose=0,\n",
    "                                  warm_start=False)\n",
    "\n",
    "run_model(model,\"GBDT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgbm\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "\n",
    "model = LGBMRegressor(learning_rate=0.07,n_estimators=100,max_depth=9,min_child_weight=1,seed=0,subsample=0.6,colsample_bytree=0.5,gamma=0.03,reg_alpha=0,reg_lambda=1)\n",
    "\n",
    "run_model(model,\"LGBM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "model = CatBoostRegressor(logging_level='Silent')\n",
    "\n",
    "run_model(model,\"CAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model= RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "run_model(model,\"rf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "model = SVR(kernel='rbf', degree=3, coef0=0.0, tol=0.01, \n",
    "           C=1.0, epsilon=0.1, shrinking=True, cache_size=200, \n",
    "           verbose=False, max_iter=-1)\n",
    "\n",
    "run_model(model,\"SVR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,Lasso,RidgeCV\n",
    "\n",
    "mse_list=[[],[],[],[],[],[],[]] # cat,lgbm,xgb,gbdt,lr\n",
    "\n",
    "i = 0\n",
    "for train, test in kfold.split(X):\n",
    "    # split & scale(optional) the dataset\n",
    "    if scale:\n",
    "        X_train, y_train  = scaler.transform(X.iloc[train]), Y.iloc[train]\n",
    "        X_test,  y_test   = scaler.transform(X.iloc[test]),  Y.iloc[test]\n",
    "    else:\n",
    "        X_train, y_train  = X.iloc[train], Y.iloc[train]\n",
    "        X_test,  y_test   = X.iloc[test],  Y.iloc[test]\n",
    "\n",
    "    # load the models\n",
    "    cat = joblib.load(filename=\"./temp_model/CAT\"+str(i))\n",
    "    lgbm = joblib.load(filename=\"./temp_model/GBDT\"+str(i))\n",
    "    xgb = joblib.load(filename=\"./temp_model/LGBM\"+str(i))\n",
    "    gbdt = joblib.load(filename=\"./temp_model/CAT\"+str(i))\n",
    "    \n",
    "    rf = joblib.load(filename=\"./temp_model/rf\"+str(i))\n",
    "    svm = joblib.load(filename=\"./temp_model/SVR\"+str(i))\n",
    "     \n",
    "    # input of lr model\n",
    "    res = np.c_[cat.predict(X_test),\n",
    "                lgbm.predict(X_test),\n",
    "                xgb.predict(X_test),\n",
    "                gbdt.predict(X_test),\n",
    "                rf.predict(X_test),\n",
    "                svm.predict(X_test),]\n",
    "    \n",
    "    # fit lf model\n",
    "    lr = RidgeCV(cv=5)\n",
    "    lr.fit(res,y_test)\n",
    "    \n",
    "    # record all the mse\n",
    "    for j in range(6):\n",
    "        mse_list[j].append(MSE(res[:,j:j+1].flatten(),y_test))\n",
    "    mse_list[6].append(MSE(lr.predict(res)     ,y_test))\n",
    "    \n",
    "    # print & save the model   \n",
    "    # print(\"lr mse:\",mse_list[4][-1])\n",
    "    joblib.dump(filename=\"./temp_model/LR\"+str(i),value=lr)\n",
    "    i+=1\n",
    "    \n",
    "print(\"============================\")\n",
    "print(\"catmse   :\",np.mean(mse_list[0]))\n",
    "print(\"lightmse :\",np.mean(mse_list[1]))\n",
    "print(\"xgmse    :\",np.mean(mse_list[2]))\n",
    "print(\"gbdtmse  :\",np.mean(mse_list[3]))\n",
    "print(\"rfmse    :\",np.mean(mse_list[4]))\n",
    "print(\"svmmse   :\",np.mean(mse_list[5]))\n",
    "print(\"lrmse    :\",np.mean(mse_list[6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=pd.read_csv('datalab/231693/zhengqi_test.txt',encoding='gbk',sep=\"\\t\").drop(['V5','V9','V11','V14','V17','V22','V28'],axis=1)\n",
    "# data_test=pd.read_csv('myspace/steam_test_washed_v.csv').drop('Unnamed: 0',axis=1)#.drop('target',axis=1)\n",
    "if scale:\n",
    "    data_test  = scaler.transform(data_test)\n",
    "prediction = []\n",
    "for i in range(15):\n",
    "    # load the models\n",
    "    cat = joblib.load(filename=\"./temp_model/CAT\"+str(i))\n",
    "    lgbm = joblib.load(filename=\"./temp_model/GBDT\"+str(i))\n",
    "    xgb = joblib.load(filename=\"./temp_model/LGBM\"+str(i))\n",
    "    gbdt = joblib.load(filename=\"./temp_model/CAT\"+str(i))\n",
    "    \n",
    "    rf = joblib.load(filename=\"./temp_model/rf\"+str(i))\n",
    "    svm = joblib.load(filename=\"./temp_model/SVR\"+str(i))\n",
    "    \n",
    "    res = np.c_[cat.predict(data_test),\n",
    "                lgbm.predict(data_test),\n",
    "                xgb.predict(data_test),\n",
    "                gbdt.predict(data_test),\n",
    "                rf.predict(data_test),\n",
    "                svm.predict(data_test),]\n",
    "    prediction.append(lr.predict(res))\n",
    "    \n",
    "res_pred=np.mean(np.array(prediction),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('myspace/remove_feature.txt', res_pred)\n",
    "\n",
    "#np.savetxt('myspace/temp/wash1_train.txt', res_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE(np.loadtxt('myspace/temp/wash_test.txt'),res_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_train = np.c_[np.loadtxt('myspace/temp/ori_train.txt'),\n",
    "                  np.loadtxt('myspace/temp/wash_train.txt'),\n",
    "                  np.loadtxt('myspace/temp/wash1_train.txt')]\n",
    "y_train = pd.read_csv('datalab/231693/zhengqi_train.txt',encoding='gbk',sep=\"\\t\")['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr =XGBRegressor()\n",
    "lr.fit(res_train,y_train)\n",
    "MSE(y_train,lr.predict(res_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test = np.c_[np.loadtxt('myspace/temp/ori_test.txt'),\n",
    "                  np.loadtxt('myspace/temp/wash_test.txt'),\n",
    "                  np.loadtxt('myspace/temp/wash1_test.txt')]\n",
    "(MSE(np.loadtxt('myspace/temp/ori_test.txt'),lr.predict(res_test)),MSE(np.loadtxt('myspace/temp/wash_test.txt'),lr.predict(res_test)),MSE(np.loadtxt('myspace/temp/wash1_test.txt'),lr.predict(res_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict(res_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.savetxt('myspace/submit_3in1.txt',lr.predict(res_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
