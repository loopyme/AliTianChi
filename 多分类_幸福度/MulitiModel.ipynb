{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('./data/washed_train_data.csv',encoding='gbk')\n",
    "data = data.fillna(0)#.drop([\"property_other\",\"invest_other\",\"edu_other\"],axis=1)\n",
    "y = data[\"happiness\"]               \n",
    "x = data.drop(['happiness','Unnamed: 0'],axis=1)\n",
    "# Split data into train and test setsPython\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(x, y,test_size=0.2,random_state=123)\n",
    "\n",
    "# scaling data\n",
    "#scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "#x_scaled = scaler.transform(x)\n",
    "#X_train_scaled = scaler.transform(X_train)\n",
    "#X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# full data train\n",
    "scaler = preprocessing.StandardScaler().fit(x)\n",
    "X_train_scaled =X_test_scaled = scaler.transform(x)\n",
    "Y_train=Y_test=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.344449471736143"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LGBMRegressor\n",
    "\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "\n",
    "LGBMmodel = LGBMRegressor(n_jobs=-1,learning_rate=0.051,\n",
    "                      n_estimators=400,\n",
    "                      num_leaves=11,\n",
    "                      reg_alpha=2.0, \n",
    "                      reg_lambda=2.1,\n",
    "                      min_child_samples=6,\n",
    "                      min_split_gain=0.5,\n",
    "                      colsample_bytree=0.2\n",
    "                     )\n",
    "\n",
    "LGBMmodel.fit(X_train_scaled,Y_train)\n",
    "mse(Y_test,LGBMmodel.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35294683007262456"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CatBoostRegressor\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "\n",
    "CBRmodel = CatBoostRegressor(colsample_bylevel=0.1,thread_count=6,silent=True,iterations=800, \n",
    "                          depth=5, \n",
    "                          learning_rate=0.051, \n",
    "                          loss_function='RMSE',\n",
    "                          l2_leaf_reg = 3)\n",
    "\n",
    "\n",
    "CBRmodel.fit(X_train_scaled,Y_train)\n",
    "mse(Y_test,CBRmodel.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2762206983756079"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gbdt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "GBDTmodel = GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
    "             learning_rate=0.051, loss='ls', max_depth=4, max_features=10,\n",
    "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "             min_impurity_split=None, min_samples_leaf=1,\n",
    "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "             n_estimators=600, presort='auto', random_state=3,\n",
    "             subsample=0.98, verbose=0, warm_start=False)\n",
    "\n",
    "GBDTmodel.fit(X_train_scaled,Y_train)\n",
    "mse(Y_test,GBDTmodel.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/x/.local/lib/python3.6/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.33960263198642837"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "#xgboost\n",
    "XGBmodel = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.1,\n",
    "       colsample_bytree=0.971, gamma=0.11, learning_rate=0.069, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=499,\n",
    "       n_jobs=-1, nthread=50, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0.1, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1.0)\n",
    "\n",
    "XGBmodel.fit(X_train_scaled, Y_train)\n",
    "mse(XGBmodel.predict(X_test_scaled),Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.15094163, -0.24200641,  1.63756683, -0.24200641])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "\n",
    "res = np.c_[LGBMmodel.predict(X_test_scaled),\n",
    "            XGBmodel.predict(X_test_scaled),\n",
    "            GBDTmodel.predict(X_test_scaled),\n",
    "            XGBmodel.predict(X_test_scaled)]\n",
    "lr = Ridge(fit_intercept=False, alpha=75)\n",
    "lr.fit(res,Y_test)\n",
    "lr.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24886135445235363"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(Y_test,lr.predict(res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24886135445235363"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_1 = np.c_[LGBMmodel.predict(X_train_scaled),\n",
    "            XGBmodel.predict(X_train_scaled),\n",
    "            GBDTmodel.predict(X_train_scaled),\n",
    "            XGBmodel.predict(X_train_scaled)]\n",
    "mse(Y_train,lr.predict(res_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data):\n",
    "    res_1 = np.c_[LGBMmodel.predict(data),\n",
    "            XGBmodel.predict(data),\n",
    "            GBDTmodel.predict(data),\n",
    "            XGBmodel.predict(data)]\n",
    "    return lr.predict(res_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv('./data/washed_test_data.csv',encoding='gbk')\n",
    "test_data = test_data.fillna(0)\n",
    "test_data_scaled = scaler.transform(test_data.drop(['Unnamed: 0'],axis=1))\n",
    "final =predict(test_data_scaled).tolist()\n",
    "res_id=[i for i in range(8001,10968+1)]\n",
    "res_csv=pd.DataFrame([final],columns=res_id,index=['happiness']).T\n",
    "res_csv.to_csv(\"/home/x/文档/git/AliTianChi/Happiness/res/res4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
